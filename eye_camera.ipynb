{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1900690/koukai/blob/main/eye_camera.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.base import doc\n",
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "uploaded = files.upload()\n",
        "filename = os.path.splitext(list(uploaded.keys())[0])[0]\n",
        "\n",
        "#視線データを読み込み必要な部分を抽出\n",
        "json_file = \"/content/\"+filename+\".json\"\n",
        "df = pd.read_json(json_file)\n",
        "df2=df[\"EyeData\"].iloc[2]\n",
        "df3 = pd.json_normalize(df2)\n",
        "df6=df3[['recomValid','recomPoint.x','recomPoint.y']]\n",
        "\n",
        "# 動画ファイルのキャプチャー\n",
        "cap = cv2.VideoCapture(\"/content/\"+filename+\".mp4\")\n",
        "\n",
        "# 動画ファイルのフレームレート取得\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "#動画のサイズを取得\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "size = (width,height)\n",
        "point_size=max(width,height)\n",
        "\n",
        "# 保存用動画ファイルのフォーマット設定\n",
        "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
        "out = cv2.VideoWriter(\"/content/\"+filename+\"_eye_point.mp4\", fourcc, fps, size)\n",
        "\n",
        "# 動画を1コマずつ取り込んで処理\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read() # キャプチャー画像の取り込み\n",
        "\n",
        "    if ret==True: # キャプチャー画像がある場合\n",
        "        # 現在時間を取得\n",
        "        time = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
        "\n",
        "        # 現在のフレーム数を取得\n",
        "        frame_n = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
        "\n",
        "        # 視点を描画\n",
        "        cv2.drawMarker(frame, (int(df6.loc[int(frame_n)][1]*width),int(df6.loc[int(frame_n)][2]*height)), (0, 0, 255),cv2.MARKER_CROSS,int(point_size/10),int(point_size/100))\n",
        "\n",
        "        # mp4動画を保存\n",
        "        out.write(frame)\n",
        "\n",
        "    else: # キャプチャー画像がない場合はループ終了\n",
        "        break\n",
        "\n",
        "cap.release() # 再生画像をクローズ\n",
        "out.release() # 出力動画ファイルをクローズ\n",
        "files.download(\"/content/\"+filename+\"_eye_point.mp4\")"
      ],
      "metadata": {
        "id": "SqsU8voNWSM7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}